{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wooihaw/kem_semarak_digital_2025/blob/main/handson_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfdjUnFEhSpV"
      },
      "source": [
        "## Hands-on 4\n",
        "#### The objective of this hands-on is to use YOLOv3 to detect a specified object in a given image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3w4VvhYTKjq"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "YOLO Object Detection on Google Colab\n",
        "\n",
        "This script demonstrates how to perform object detection using a pre-trained YOLOv3 model\n",
        "on Google Colab. It allows users to upload an image, specify an object class to detect,\n",
        "and then visualizes the detection results or informs if the object is not supported or not found.\n",
        "\"\"\"\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. Download YOLOv3 weights and configuration files ---\n",
        "# These are standard files for YOLOv3. You might need to adjust paths if using a different YOLO version.\n",
        "print(\"Downloading YOLOv3 weights and configuration files...\")\n",
        "!wget -nc https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov3.weights\n",
        "!wget -nc https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
        "!wget -nc https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\n",
        "print(\"Download complete.\")\n",
        "\n",
        "# --- 2. Load YOLO model ---\n",
        "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "# Load COCO class names (YOLOv3 was trained on COCO dataset)\n",
        "with open(\"coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "print(f\"YOLO model loaded. Supported classes: {len(classes)}\")\n",
        "\n",
        "print(\"\\n--- List of 80 objects that can be detected by this YOLO model (COCO dataset) ---\")\n",
        "# Print classes in a readable format, e.g., columns or numbered list\n",
        "num_columns = 4 # Adjust as needed\n",
        "for i, obj_class in enumerate(classes):\n",
        "    print(f\"{i+1:3d}. {obj_class:<15}\", end=\"\") # 15 for padding\n",
        "    if (i + 1) % num_columns == 0:\n",
        "        print() # New line after every 'num_columns' items\n",
        "if (len(classes) % num_columns != 0): # Print final newline if needed\n",
        "    print()\n",
        "print(\"--------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "# --- 3. Function to perform object detection ---\n",
        "def detect_objects(image_path, target_class=None, confidence_threshold=0.5, nms_threshold=0.4):\n",
        "    \"\"\"\n",
        "    Performs object detection on an image using the loaded YOLO model.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the input image.\n",
        "        target_class (str, optional): The specific object class to highlight.\n",
        "                                     If None, all detected objects are shown.\n",
        "        confidence_threshold (float): Minimum confidence to consider a detection.\n",
        "        nms_threshold (float): Non-maximum suppression threshold.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (processed_image, found_target)\n",
        "               processed_image: Image with bounding boxes and labels (or original if no detections).\n",
        "               found_target: True if the target_class was detected, False otherwise.\n",
        "    \"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(f\"Error: Could not load image from {image_path}\")\n",
        "        return None, False\n",
        "\n",
        "    height, width, channels = img.shape\n",
        "\n",
        "    # Detecting objects\n",
        "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    outs = net.forward(output_layers)\n",
        "\n",
        "    # Showing information on the screen\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    found_target = False\n",
        "\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > confidence_threshold:\n",
        "                # Object detected\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "\n",
        "                # Rectangle coordinates\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    # Apply Non-Maximum Suppression to remove redundant overlapping boxes\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, confidence_threshold, nms_threshold)\n",
        "\n",
        "    font = cv2.FONT_HERSHEY_PLAIN\n",
        "    colors = np.random.uniform(0, 255, size=(len(classes), 3)) # Generate unique colors for classes\n",
        "\n",
        "    if len(indexes) > 0:\n",
        "        for i in indexes.flatten():\n",
        "            x, y, w, h = boxes[i]\n",
        "            label = str(classes[class_ids[i]])\n",
        "            confidence = str(round(confidences[i], 2))\n",
        "            color = colors[class_ids[i]]\n",
        "\n",
        "            if target_class is None or label.lower() == target_class.lower():\n",
        "                cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
        "                cv2.putText(img, label + \" \" + confidence, (x, y - 10), font, 1, color, 2)\n",
        "                if target_class is not None and label.lower() == target_class.lower():\n",
        "                    found_target = True\n",
        "    return img, found_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFUXIDwiVXrF"
      },
      "outputs": [],
      "source": [
        "# --- 4. Main execution in Colab ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n--- YOLO Object Detection Demo ---\")\n",
        "    print(\"Please upload an image to perform detection.\")\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"No image uploaded. Exiting.\")\n",
        "    else:\n",
        "        for fn in uploaded.keys():\n",
        "            image_path = fn\n",
        "            print(f\"Image '{image_path}' uploaded.\")\n",
        "\n",
        "            while True:\n",
        "                user_input_object = input(\"\\nEnter the object you want to detect (e.g., 'car', 'dog', 'person'). Type 'done' to exit: \").strip()\n",
        "\n",
        "                if user_input_object.lower() == 'done':\n",
        "                    break\n",
        "\n",
        "                # Check if the requested object is supported by YOLO (i.e., in COCO classes)\n",
        "                supported_classes_lower = [c.lower() for c in classes]\n",
        "                if user_input_object.lower() not in supported_classes_lower:\n",
        "                    print(f\"'{user_input_object}' is not a supported object class by this YOLO model (COCO dataset). Please try another.\")\n",
        "                    continue\n",
        "\n",
        "                print(f\"Attempting to detect '{user_input_object}' in '{image_path}'...\")\n",
        "                processed_img, target_found = detect_objects(image_path, target_class=user_input_object)\n",
        "\n",
        "                if processed_img is not None:\n",
        "                    plt.figure(figsize=(10, 8))\n",
        "                    plt.imshow(cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB))\n",
        "                    plt.axis('off')\n",
        "                    plt.title(f\"Detection Results for '{user_input_object}'\")\n",
        "                    plt.show()\n",
        "\n",
        "                    if target_found:\n",
        "                        print(f\"Success! '{user_input_object}' detected in the image.\")\n",
        "                    else:\n",
        "                        print(f\"'{user_input_object}' was supported but not detected in the image with current confidence settings.\")\n",
        "                else:\n",
        "                    print(\"Could not process the image for detection.\")\n",
        "\n",
        "            print(\"\\nDemo finished.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}