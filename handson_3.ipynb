{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wooihaw/kem_semarak_digital_2025/blob/main/handson_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR2vA3DKfU5Y"
      },
      "source": [
        "## Hands-on 3\n",
        "#### The objective of this hands-on is to train a convolutional neural network (CNN) to recognize the handwritten digits (0 - 9)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tLf-R5DfU5a"
      },
      "outputs": [],
      "source": [
        "pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTGh9k866VHq"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# plot 4 images as gray scale\n",
        "sp1 = plt.subplot(141)\n",
        "sp1.axis(False)\n",
        "sp1.set_title(y_train[0])\n",
        "sp1.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
        "sp2 = plt.subplot(142)\n",
        "sp2.axis(False)\n",
        "sp2.set_title(y_train[1])\n",
        "sp2.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
        "sp3 = plt.subplot(143)\n",
        "sp3.axis(False)\n",
        "sp3.set_title(y_train[2])\n",
        "sp3.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
        "sp4 = plt.subplot(144)\n",
        "sp4.axis(False)\n",
        "sp4.set_title(y_train[3])\n",
        "sp4.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44LWqaCsfU5c"
      },
      "outputs": [],
      "source": [
        "# reshape to be [samples][channels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "# define model for LeNet\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=(28, 28, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(50, (5, 5), padding=\"same\", activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64)\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Error: %.2f%%\" % (100-scores[1]*100))\n",
        "\n",
        "# Insert the codes to serialize model to JSON\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.weights.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "# Generate and save plots\n",
        "matplotlib.use('Agg')\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'], 'b', label='train') # Changed 'acc' to 'accuracy'\n",
        "plt.plot(history.history['val_accuracy'], 'g', label='test') # Changed 'val_acc' to 'val_accuracy'\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('acc.jpg')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], 'b', label='train')\n",
        "plt.plot(history.history['val_loss'], 'g', label='test')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('loss.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhKJygVUfU5c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Make predition (change index to a number between 0 and 9999)\n",
        "try:\n",
        "  index = int(input(\"Enter an index between 0 and 9999: \"))\n",
        "  assert 0 <= index < 10000, \"The index should be between 0 and 9999\"\n",
        "except Exception as e:\n",
        "  print(\"Error: \", e)\n",
        "else:\n",
        "  res = model.predict(X_test[index].reshape(1, 28, 28, 1))\n",
        "  print(res)\n",
        "  print(f'Predicted label: {np.argmax(res)}')\n",
        "\n",
        "  # Display the test image and show the actual label\n",
        "  plt.axis(False)\n",
        "  plt.title(f'Actual label: {y_test[index].argmax()}')\n",
        "  plt.imshow(X_test[index].reshape(28, 28) * 255, cmap='gray')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeKYMrXqr81F"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import cv2 # Using OpenCV for image processing\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import model_from_json\n",
        "import os # To check if model files exist\n",
        "\n",
        "print(\"TensorFlow Version:\", tf.__version__)\n",
        "print(\"Gradio Version:\", gr.__version__)\n",
        "print(\"OpenCV Version:\", cv2.__version__)\n",
        "\n",
        "# --- Configuration ---\n",
        "MODEL_JSON_PATH = 'model.json'\n",
        "MODEL_WEIGHTS_PATH = 'model.weights.h5'\n",
        "INPUT_SHAPE = (28, 28) # Expected input shape for the model (height, width)\n",
        "\n",
        "# --- Load Model (Do this once outside the prediction function) ---\n",
        "net = None\n",
        "model_loaded = False\n",
        "\n",
        "if os.path.exists(MODEL_JSON_PATH) and os.path.exists(MODEL_WEIGHTS_PATH):\n",
        "    try:\n",
        "        # Load model architecture from JSON\n",
        "        with open(MODEL_JSON_PATH, 'r') as json_file:\n",
        "            loaded_model_json = json_file.read()\n",
        "        net = model_from_json(loaded_model_json)\n",
        "\n",
        "        # Load weights into the model\n",
        "        net.load_weights(MODEL_WEIGHTS_PATH)\n",
        "\n",
        "        # Compile the model (often necessary after loading, even if just for prediction)\n",
        "        # Use standard settings; adjust if your model requires specific ones.\n",
        "        net.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        print(\"Keras Model loaded successfully from disk.\")\n",
        "        model_loaded = True\n",
        "        # Optional: Print model summary\n",
        "        # net.summary()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading Keras model: {e}\")\n",
        "        print(\"Please ensure 'model.json' and 'model.weights.h5' are uploaded correctly.\")\n",
        "else:\n",
        "    print(f\"Error: Model files not found.\")\n",
        "    print(f\"Please make sure '{MODEL_JSON_PATH}' and '{MODEL_WEIGHTS_PATH}' exist in the current directory.\")\n",
        "\n",
        "# --- Prediction Function ---\n",
        "def recognize_digit(image):\n",
        "    # --- START DEBUGGING PRINTS ---\n",
        "    print(\"-\" * 20)\n",
        "    print(f\"Received input type: {type(image)}\")\n",
        "    # Limit printing the full value if it's large (like an image array or complex dict)\n",
        "    if isinstance(image, (dict, np.ndarray)) and image is not None:\n",
        "         # Try printing keys for dict, shape for array, else snippet\n",
        "         if isinstance(image, dict):\n",
        "              print(f\"Received input value (dict keys): {image.keys()}\")\n",
        "         elif hasattr(image, 'shape'):\n",
        "              print(f\"Received input value (array shape): {image.shape}\")\n",
        "         else:\n",
        "              print(f\"Received input value: {str(image)[:100]}...\") # Print snippet\n",
        "    else:\n",
        "         print(f\"Received input value: {image}\") # Print simple types directly\n",
        "    print(\"-\" * 20)\n",
        "    # --- END DEBUGGING PRINTS ---\n",
        "\n",
        "    # Handle None case FIRST\n",
        "    if image is None:\n",
        "        print(\"Input image is None, returning.\")\n",
        "        return \"Please draw a digit.\", None\n",
        "\n",
        "    # --- Check if it's a dictionary and try to extract 'composite' image ---\n",
        "    if isinstance(image, dict):\n",
        "        print(\"Input is a dictionary. Keys:\", image.keys())\n",
        "        # --- Updated Logic: Check for 'composite' key ---\n",
        "        if 'composite' in image and isinstance(image['composite'], np.ndarray):\n",
        "            print(\"Found 'composite' key with numpy array, using it.\")\n",
        "            image = image['composite'] # Extract the composite image array\n",
        "        else:\n",
        "            # If 'composite' key doesn't exist or isn't a numpy array\n",
        "            print(\"Error: Input is a dictionary but cannot find valid 'composite' image data.\")\n",
        "            # Print types of dictionary values for more detail if needed\n",
        "            for key in image:\n",
        "                 if image[key] is not None:\n",
        "                      print(f\"  Key '{key}' type: {type(image[key])}, Shape/Len: {getattr(image[key], 'shape', len(getattr(image[key], '__dict__', image[key])))}\")\n",
        "                 else:\n",
        "                      print(f\"  Key '{key}' type: None\")\n",
        "            return \"Error: Unexpected dictionary format from Sketchpad.\", None\n",
        "    # --- End of dictionary handling ---\n",
        "\n",
        "    # --- Defensive Check for shape attribute ---\n",
        "    # Now, 'image' should be a NumPy array (either originally or extracted)\n",
        "    if not hasattr(image, 'shape'):\n",
        "         print(f\"Error: Input STILL does not have 'shape' after processing. Type is {type(image)}\")\n",
        "         return \"Error: Unexpected input format after processing.\", None\n",
        "\n",
        "    # --- Original code resumes here ---\n",
        "    # Check image dimensions and convert to grayscale if necessary\n",
        "    print(f\"Processing image with shape: {image.shape}\")\n",
        "    if len(image.shape) == 2: # Grayscale already\n",
        "        gray_image = image\n",
        "        print(\"Image is grayscale.\")\n",
        "    elif len(image.shape) == 3 and image.shape[2] == 4: # RGBA\n",
        "        # Sketchpad composite might be RGBA\n",
        "        print(\"Image is RGBA, converting to grayscale.\")\n",
        "        # Convert RGBA to Grayscale - handle transparency appropriately if needed\n",
        "        # A simple approach is to convert to RGB first, then Gray\n",
        "        # Or directly, ensuring background color handling if alpha is used\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_RGBA2GRAY) # OpenCV handles RGBA->Gray\n",
        "    elif len(image.shape) == 3 and image.shape[2] == 3: # RGB\n",
        "        print(\"Image is RGB, converting to grayscale.\")\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    else:\n",
        "        print(f\"Error: Input image has unexpected shape: {image.shape}\")\n",
        "        return \"Error: Invalid image dimensions.\", None\n",
        "\n",
        "    # --- Continue with the rest of your processing ---\n",
        "    # (Manual Inversion, Thresholding, Resizing, Prediction...)\n",
        "\n",
        "    # Ensure manual inversion is still present if needed (white-on-black)\n",
        "    print(\"Inverting image colors (assuming white on black needed).\")\n",
        "    gray_image = 255 - gray_image\n",
        "\n",
        "    # Optional: Apply thresholding\n",
        "    print(\"Applying threshold.\")\n",
        "    _, processed_image = cv2.threshold(gray_image, 50, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Resize to the target input size\n",
        "    print(f\"Resizing image to {INPUT_SHAPE}.\")\n",
        "    processed_image = cv2.resize(processed_image, INPUT_SHAPE, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # Reshape and Normalize\n",
        "    print(\"Reshaping and normalizing for model.\")\n",
        "    blob = processed_image.reshape(1, INPUT_SHAPE[0], INPUT_SHAPE[1], 1).astype('float32')\n",
        "    blob /= 255.0\n",
        "\n",
        "    # Make Prediction\n",
        "    print(\"Making prediction.\")\n",
        "    try:\n",
        "        predictions = net.predict(blob)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during prediction: {e}\")\n",
        "        return f\"Prediction error: {e}\", processed_image # Return error and processed image\n",
        "\n",
        "    # Format Output\n",
        "    print(\"Formatting predictions.\")\n",
        "    confidences = {str(i): float(predictions[0][i]) for i in range(len(predictions[0]))}\n",
        "\n",
        "    print(\"Returning results.\")\n",
        "    return confidences, processed_image\n",
        "\n",
        "# --- Create Gradio Interface ---\n",
        "if model_loaded:\n",
        "# Define Input and Output Components\n",
        "    input_sketchpad = gr.Sketchpad(\n",
        "        label=\"Draw a Digit (0-9)\",\n",
        "        image_mode='L'\n",
        "    )\n",
        "\n",
        "    output_label = gr.Label(\n",
        "        num_top_classes=3,\n",
        "        label=\"Predictions\"\n",
        "    )\n",
        "\n",
        "    # Corrected gr.Image definition\n",
        "    output_processed_image = gr.Image(\n",
        "        label=\"Processed Input (28x28)\",\n",
        "        # shape=(INPUT_SHAPE[1], INPUT_SHAPE[0]), # This caused the error\n",
        "        width=INPUT_SHAPE[1],  # Set width explicitly (should be 28)\n",
        "        height=INPUT_SHAPE[0], # Set height explicitly (should be 28)\n",
        "        image_mode='L'         # Keep image mode as grayscale\n",
        "    )\n",
        "\n",
        "    # Create the Interface\n",
        "    iface = gr.Interface(\n",
        "        fn=recognize_digit,\n",
        "        inputs=input_sketchpad,\n",
        "        outputs=[output_label, output_processed_image], # List of outputs\n",
        "        live=False,\n",
        "        title=\"Handwritten Digit Recognizer\",\n",
        "        description=\"Draw a single digit (0-9) in the box below. The model will predict the digit in real-time. Ensure the model files ('model.json', 'model.weights.h5') are uploaded.\"\n",
        "    )\n",
        "\n",
        "    # Launch the Interface (share=True provides a public link for Colab)\n",
        "    iface.launch(share=True, debug=True) # debug=True can help troubleshoot\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Gradio Interface cannot start because the model failed to load. ---\")\n",
        "    print(\"Please check the file paths and ensure the model files are correct and uploaded.\")\n",
        "    # You could potentially launch a simple Gradio interface showing the error message\n",
        "    # def show_error():\n",
        "    #     return \"Model Loading Failed. Check Colab output/logs.\"\n",
        "    # gr.Interface(fn=show_error, inputs=None, outputs=\"text\", title=\"Error\", description=\"Could not load the digit recognition model.\").launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}